{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "D:\\Anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "D:\\Anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78571429 0.85714286 0.73809524 0.8452381  0.85714286 0.72619048\n",
      " 0.82142857 0.77108434 0.71084337 0.84337349]\n",
      "Mean score: 0.7956 (+/-0.0179)\n",
      "Accuracy for training: 0.972520908005\n",
      "Accuracy for testing: 0.789285714286\n",
      "Classification Report:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "Not related or not informative     0.9333    0.6131    0.7401       137\n",
      "       Related and informative     0.7211    0.9580    0.8228       143\n",
      "\n",
      "                   avg / total     0.8249    0.7893    0.7823       280\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 84  53]\n",
      " [  6 137]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# plt.style.use('ggplot')\n",
    "# % matplotlib inline\n",
    "\n",
    "df = pd.read_csv('CrisisLexT26/2012_Colorado_wildfires/2012_Colorado_wildfires-tweets_labeled.csv') # change the file location if needed\n",
    "\n",
    "col_dict = {}\n",
    "for old_feature in df.columns.values:\n",
    "    col_dict.update({old_feature: old_feature.replace(' ','')})\n",
    "df.rename(columns=col_dict, inplace=True)\n",
    "\n",
    "df.Informativeness.value_counts()\n",
    "\n",
    "df = df[df.InformationSource != 'Government']\n",
    "df = df[df.Informativeness!='Not applicable'].reset_index(drop=True)\n",
    "df.Informativeness.value_counts()\n",
    "\n",
    "label = ['Not related or not informative'] * df.shape[0]\n",
    "idx = df.index[df.Informativeness == 'Related and informative'].tolist()\n",
    "for i in idx: label[i] = 'Related and informative'\n",
    "df['label'] = pd.Series(label)\n",
    "\n",
    "df.head()\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import preprocessor as p\n",
    "\n",
    "emoji_re = \"['\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF']\"\n",
    "emojis = [regexp_tokenize(t, emoji_re) for t in df.TweetText]\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.SMILEY)\n",
    "all_tweets = [p.clean(t).lower() for t in df.TweetText]\n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "all_tokens = [tknzr.tokenize(t) for t in all_tweets]\n",
    "# en_stop = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "processed_texts = []  # preprocessed tweets\n",
    "\n",
    "for i in range(len(all_tokens)):\n",
    "    processed_texts.append(' '.join([lemmatizer.lemmatize(t) for t in all_tokens[i]]))\n",
    "\n",
    "df['ProcessedText'] = pd.Series(processed_texts)\n",
    "df.head()\n",
    "\n",
    "split_percentage = 0.25\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(df.ProcessedText, df.label, test_size=split_percentage, random_state=42) \n",
    "hash_pp_vec = HashingVectorizer(analyzer='word', non_negative=True)\n",
    "X_hash_pp_train = hash_pp_vec.fit_transform(X_train2)  \n",
    "X_hash_pp_test = hash_pp_vec.transform(X_test2)\n",
    "\n",
    "mnb_hash_pp = MultinomialNB(0.1, False)\n",
    "parameters = {'fit_prior':('True', 'False'), 'alpha':list(np.arange(0.1, 2, 0.1))}\n",
    "# clf = GridSearchCV(mnb_hash_pp, parameters)\n",
    "# clf.fit(X_hash_pp_train, y_train2)\n",
    "mnb_hash_pp.fit(X_hash_pp_train, y_train2)\n",
    "# mnb_hash_pp = clf.best_estimator_\n",
    "# print clf.best_params_\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, KFold \n",
    "from scipy.stats import sem \n",
    "\n",
    "def evaluate_cross_validation(clf, X, y, K):\n",
    "    cv = KFold(len(y), K, shuffle=True, random_state=0)  \n",
    "    scores = cross_val_score(clf, X, y, cv=cv) \n",
    "    print scores\n",
    "    print (\"Mean score: {0:.4f} (+/-{1:.4f})\").format(np.mean(scores), sem(scores))\n",
    "\n",
    "evaluate_cross_validation(mnb_hash_pp, X_hash_pp_train, y_train2, 10)\n",
    "\n",
    "print 'Accuracy for training: {}'.format(mnb_hash_pp.score(X_hash_pp_train, y_train2))\n",
    "print 'Accuracy for testing: {}'.format(mnb_hash_pp.score(X_hash_pp_test, y_test2))\n",
    "\n",
    "y_hash_pp_predict = mnb_hash_pp.predict(X_hash_pp_test) \n",
    "print \"Classification Report:\" \n",
    "print metrics.classification_report(y_test2,y_hash_pp_predict,digits=4) \n",
    "print \"Confusion Matrix:\" \n",
    "print metrics.confusion_matrix(y_test2,y_hash_pp_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All 3 other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Related and informative          2200\n",
       "Related - but not informative     593\n",
       "Not related                       573\n",
       "Not applicable                     33\n",
       "Name: Informativeness, dtype: int64"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('CrisisLexT26/2013_Colorado_floods/2013_Colorado_floods-tweets_labeled.csv') # change the file location if needed\n",
    "df2 = pd.read_csv('CrisisLexT26/2013_Australia_bushfire/2013_Australia_bushfire-tweets_labeled.csv') # change the file location if needed\n",
    "df3 = pd.read_csv('CrisisLexT26/2013_Queensland_floods/2013_Queensland_floods-tweets_labeled.csv') # change the file location if needed\n",
    "df = pd.concat([df1, df2, df3])\n",
    "\n",
    "col_dict = {}\n",
    "for old_feature in df.columns.values:\n",
    "    col_dict.update({old_feature: old_feature.replace(' ','')})\n",
    "df.rename(columns=col_dict, inplace=True)\n",
    "\n",
    "df.Informativeness.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Related and informative          1958\n",
       "Related - but not informative     577\n",
       "Not related                       573\n",
       "Name: Informativeness, dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.InformationSource != 'Government']\n",
    "df = df[df.Informativeness!='Not applicable'].reset_index(drop=True)\n",
    "df.Informativeness.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetID</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>InformationSource</th>\n",
       "      <th>InformationType</th>\n",
       "      <th>Informativeness</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>376843697943769088</td>\n",
       "      <td>#Longmont #CO The Tiny Tim Center is now #hiri...</td>\n",
       "      <td>Not labeled</td>\n",
       "      <td>Not labeled</td>\n",
       "      <td>Not related</td>\n",
       "      <td>Not related or not informative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>378011169883037697</td>\n",
       "      <td>RT @dlfluegge: Crazy Flooding in Boulder, Colo...</td>\n",
       "      <td>Media</td>\n",
       "      <td>Sympathy and support</td>\n",
       "      <td>Related - but not informative</td>\n",
       "      <td>Not related or not informative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>378020179214491649</td>\n",
       "      <td>Here's the #boulderflood video that's circulat...</td>\n",
       "      <td>Outsiders</td>\n",
       "      <td>Other Useful Information</td>\n",
       "      <td>Related and informative</td>\n",
       "      <td>Related and informative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>378026101588496385</td>\n",
       "      <td>RT @passantino: Video: Severe flooding hits ne...</td>\n",
       "      <td>Media</td>\n",
       "      <td>Other Useful Information</td>\n",
       "      <td>Related and informative</td>\n",
       "      <td>Related and informative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378029784204206080</td>\n",
       "      <td>Crazy Flooding in Boulder, Colorado http://t.c...</td>\n",
       "      <td>Media</td>\n",
       "      <td>Other Useful Information</td>\n",
       "      <td>Related and informative</td>\n",
       "      <td>Related and informative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TweetID                                          TweetText  \\\n",
       "0  376843697943769088  #Longmont #CO The Tiny Tim Center is now #hiri...   \n",
       "1  378011169883037697  RT @dlfluegge: Crazy Flooding in Boulder, Colo...   \n",
       "2  378020179214491649  Here's the #boulderflood video that's circulat...   \n",
       "3  378026101588496385  RT @passantino: Video: Severe flooding hits ne...   \n",
       "4  378029784204206080  Crazy Flooding in Boulder, Colorado http://t.c...   \n",
       "\n",
       "  InformationSource           InformationType                Informativeness  \\\n",
       "0       Not labeled               Not labeled                    Not related   \n",
       "1             Media      Sympathy and support  Related - but not informative   \n",
       "2         Outsiders  Other Useful Information        Related and informative   \n",
       "3             Media  Other Useful Information        Related and informative   \n",
       "4             Media  Other Useful Information        Related and informative   \n",
       "\n",
       "                            label  \n",
       "0  Not related or not informative  \n",
       "1  Not related or not informative  \n",
       "2         Related and informative  \n",
       "3         Related and informative  \n",
       "4         Related and informative  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = ['Not related or not informative'] * df.shape[0]\n",
    "idx = df.index[df.Informativeness == 'Related and informative'].tolist()\n",
    "for i in idx: label[i] = 'Related and informative'\n",
    "df['label'] = pd.Series(label)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetID</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>InformationSource</th>\n",
       "      <th>InformationType</th>\n",
       "      <th>Informativeness</th>\n",
       "      <th>label</th>\n",
       "      <th>ProcessedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>381102510322499584</td>\n",
       "      <td>RT @TotalTrafficDEN: #Longmont closed on Hwy 2...</td>\n",
       "      <td>Media</td>\n",
       "      <td>Caution and advice</td>\n",
       "      <td>Related and informative</td>\n",
       "      <td>Related and informative</td>\n",
       "      <td>rt @totaltrafficden : #longmont closed on hwy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>392530239693139968</td>\n",
       "      <td>RT @702sydney: Incredible photo of @NSWRFS fir...</td>\n",
       "      <td>Media</td>\n",
       "      <td>Affected individuals</td>\n",
       "      <td>Related and informative</td>\n",
       "      <td>Related and informative</td>\n",
       "      <td>rt @702sydney : incredible photo of @nswrfs fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>392160092373528577</td>\n",
       "      <td>RT @MarshallThomasB: Abbott using the NSW bush...</td>\n",
       "      <td>Outsiders</td>\n",
       "      <td>Other Useful Information</td>\n",
       "      <td>Related - but not informative</td>\n",
       "      <td>Not related or not informative</td>\n",
       "      <td>rt @marshallthomasb : abbott using the nsw bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>379140385554964480</td>\n",
       "      <td>Pray for the certain parts in Colorado that ar...</td>\n",
       "      <td>Outsiders</td>\n",
       "      <td>Sympathy and support</td>\n",
       "      <td>Related - but not informative</td>\n",
       "      <td>Not related or not informative</td>\n",
       "      <td>pray for the certain part in colorado that are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>392702000640430082</td>\n",
       "      <td>RT @byers_brian: We are giving away World Seri...</td>\n",
       "      <td>Not labeled</td>\n",
       "      <td>Not labeled</td>\n",
       "      <td>Not related</td>\n",
       "      <td>Not related or not informative</td>\n",
       "      <td>rt @byers_brian : we are giving away world ser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TweetID                                          TweetText  \\\n",
       "711   381102510322499584  RT @TotalTrafficDEN: #Longmont closed on Hwy 2...   \n",
       "1599  392530239693139968  RT @702sydney: Incredible photo of @NSWRFS fir...   \n",
       "1510  392160092373528577  RT @MarshallThomasB: Abbott using the NSW bush...   \n",
       "191   379140385554964480  Pray for the certain parts in Colorado that ar...   \n",
       "1647  392702000640430082  RT @byers_brian: We are giving away World Seri...   \n",
       "\n",
       "     InformationSource           InformationType  \\\n",
       "711              Media        Caution and advice   \n",
       "1599             Media      Affected individuals   \n",
       "1510         Outsiders  Other Useful Information   \n",
       "191          Outsiders      Sympathy and support   \n",
       "1647       Not labeled               Not labeled   \n",
       "\n",
       "                    Informativeness                           label  \\\n",
       "711         Related and informative         Related and informative   \n",
       "1599        Related and informative         Related and informative   \n",
       "1510  Related - but not informative  Not related or not informative   \n",
       "191   Related - but not informative  Not related or not informative   \n",
       "1647                    Not related  Not related or not informative   \n",
       "\n",
       "                                          ProcessedText  \n",
       "711   rt @totaltrafficden : #longmont closed on hwy ...  \n",
       "1599  rt @702sydney : incredible photo of @nswrfs fi...  \n",
       "1510  rt @marshallthomasb : abbott using the nsw bus...  \n",
       "191   pray for the certain part in colorado that are...  \n",
       "1647  rt @byers_brian : we are giving away world ser...  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.SMILEY)\n",
    "all_tweets = [p.clean(t).lower() for t in df.TweetText]\n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "all_tokens = [tknzr.tokenize(t) for t in all_tweets]\n",
    "#en_stop = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "processed_texts = []  # preprocessed tweets\n",
    "\n",
    "for i in range(len(all_tokens)):\n",
    "    processed_texts.append(' '.join([lemmatizer.lemmatize(t) for t in all_tokens[i]]))\n",
    "\n",
    "df['ProcessedText'] = pd.Series(processed_texts)\n",
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "D:\\Anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "step = 1\n",
    "threshold = 0.75\n",
    "sublen = df.shape[0]/step\n",
    "marks = [i*sublen for i in range(step)]\n",
    "marks.append(df.shape[0]-1)\n",
    "for i in range(step):\n",
    "    test = df.ProcessedText[marks[i]:marks[i+1]]\n",
    "    test_hash = hash_pp_vec.transform(test)\n",
    "    predict_hash = mnb_hash_pp.predict(test_hash)\n",
    "    probability = mnb_hash_pp.predict_proba(test_hash)\n",
    "    new_text_list = []\n",
    "    new_label_list = []\n",
    "    for j in range(test.shape[0]):\n",
    "        if probability[j][0] >= threshold or probability[j][1] >= threshold:\n",
    "            new_text_list.append(test.values[j])\n",
    "            new_label_list.append(predict_hash[j])\n",
    "    new_text = np.asarray(new_text_list)\n",
    "    new_label = np.asarray(new_label_list)\n",
    "    new_text_hash = hash_pp_vec.transform(new_text)\n",
    "    mnb_hash_pp.partial_fit(new_text_hash, new_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "Not related or not informative     0.9030    0.3643    0.5192      1150\n",
      "       Related and informative     0.7235    0.9770    0.8314      1958\n",
      "\n",
      "                   avg / total     0.7899    0.7503    0.7159      3108\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 419  731]\n",
      " [  45 1913]]\n",
      "Accuracy:\n",
      "0.7503217503217503\n"
     ]
    }
   ],
   "source": [
    "X_hash_pp_test = hash_pp_vec.transform(df.ProcessedText)\n",
    "\n",
    "y_hash_pp_predict = mnb_hash_pp.predict(X_hash_pp_test)\n",
    "\n",
    "print \"Classification Report:\" \n",
    "print metrics.classification_report(df.label,y_hash_pp_predict, digits=4) \n",
    "print \"Confusion Matrix:\" \n",
    "print metrics.confusion_matrix(df.label,y_hash_pp_predict)\n",
    "print \"Accuracy:\"\n",
    "print metrics.accuracy_score(df.label,y_hash_pp_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
